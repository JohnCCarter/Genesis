{"id": "batch_req_689ed9e7597081909c6e8ee82741f42a", "custom_id": "demo-1", "response": {"status_code": 200, "request_id": "20f2797712ef2f4c59fcc74137aac071", "body": {"id": "resp_689ed9d2cffc81a3947b7a9c5f42224e02de5b11e69fa095", "object": "response", "created_at": 1755240914, "status": "completed", "background": false, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-5-2025-08-07", "output": [{"id": "rs_689ed9d3d9f081a3a0ffc3c27d05887c02de5b11e69fa095", "type": "reasoning", "summary": []}, {"id": "msg_689ed9d56fe481a39078daf234248c5102de5b11e69fa095", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "Genesis trading bot decouples its UI from the core engine, splitting frontend and backend for better modularity and scalability."}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "reasoning": {"effort": "medium", "summary": null}, "safety_identifier": null, "service_tier": "auto", "store": true, "temperature": 1.0, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 28, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 222, "output_tokens_details": {"reasoning_tokens": 192}, "total_tokens": 250}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_689ed9e777548190bcb111b042b50153", "custom_id": "demo-2", "response": {"status_code": 200, "request_id": "5ca0facca3e888db09b315b192afbcd5", "body": {"id": "resp_689ed97c6fc8819c9298a71e201253d0014350e2c04b0164", "object": "response", "created_at": 1755240828, "status": "completed", "background": false, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-5-2025-08-07", "output": [{"id": "rs_689ed97cdd9c819cae18c149d1c00355014350e2c04b0164", "type": "reasoning", "summary": []}, {"id": "msg_689ed98062d0819c8f35491dfbc3b5d4014350e2c04b0164", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "- Cost-efficient at scale: crunch terabytes of logs in parallel during off-hours, use spot/preemptible compute, and compact/partition data to cheap storage.\n- Deterministic and auditable: immutable inputs, versioned code, and idempotent reruns/backfills enable compliant T+1 reports, surveillance, and forensics.\n- Operationally resilient: handles spikes and outages with retries and backlog draining, isolates failures, and prevents data loss without real-time complexity."}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "reasoning": {"effort": "medium", "summary": null}, "safety_identifier": null, "service_tier": "auto", "store": true, "temperature": 1.0, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 27, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 550, "output_tokens_details": {"reasoning_tokens": 448}, "total_tokens": 577}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_689ed9e76d3481909037fee75c28366a", "custom_id": "demo-3", "response": {"status_code": 200, "request_id": "c59a7d05df85630e49c0647b557df827", "body": {"id": "resp_689ed9d2976c819eb131f25ad9b0a9670f1fabb4e1af34f3", "object": "response", "created_at": 1755240914, "status": "completed", "background": false, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-5-2025-08-07", "output": [{"id": "rs_689ed9d33dec819ea17fc6e7623558950f1fabb4e1af34f3", "type": "reasoning", "summary": []}, {"id": "msg_689ed9d388b4819ea50590d9b782b5bc0f1fabb4e1af34f3", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "Hello world"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "reasoning": {"effort": "medium", "summary": null}, "safety_identifier": null, "service_tier": "auto", "store": true, "temperature": 1.0, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 22, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 8, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 30}, "user": null, "metadata": {}}}, "error": null}
